{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('./handlers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка работы цепочек слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.words import Word, ChainOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1():\n",
    "    chain = ChainOfWords()\n",
    "\n",
    "    word = Word('1', 1)\n",
    "    print(word)\n",
    "    chain.add_word(word)\n",
    "    print(word)\n",
    "    print('first:', chain.first)\n",
    "    print('last:', chain.last)\n",
    "    print()\n",
    "\n",
    "    word_was_1 = word\n",
    "    word = Word('2', 2)\n",
    "    print(word)\n",
    "    chain.add_word(word)\n",
    "    print(word)\n",
    "    print(word_was_1)\n",
    "    print('first:', chain.first)\n",
    "    print('last:', chain.last)\n",
    "    print()\n",
    "\n",
    "    word_was_2 = word\n",
    "    word = Word('3', 3)\n",
    "    print(word)\n",
    "    chain.add_word(word)\n",
    "    print(word)\n",
    "    print(word_was_1)\n",
    "    print(word_was_2)\n",
    "    print('first:', chain.first)\n",
    "    print('last:', chain.last)\n",
    "    print()\n",
    "\n",
    "    for w in chain:\n",
    "        print(w)\n",
    "    print()\n",
    "\n",
    "    print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_2():\n",
    "    chain = ChainOfWords()\n",
    "    word_1 = Word('1', 1)\n",
    "    chain.add_word(word_1)\n",
    "    word_2 = Word('2', 2)\n",
    "    chain.add_word(word_2)\n",
    "    word_3 = Word('3', 3)\n",
    "    chain.add_word(word_3)\n",
    "    word_4 = Word('4', 4)\n",
    "    chain.add_word(word_4)\n",
    "\n",
    "    chain.remove_word(word_4)\n",
    "    for w in chain:\n",
    "        print(w)\n",
    "    print()\n",
    "\n",
    "    chain.add_word(word_4)\n",
    "    chain.remove_word(word_2)\n",
    "    for w in chain:\n",
    "        print(w)\n",
    "    print()\n",
    "\n",
    "    chain.remove_word(word_2)\n",
    "    for w in chain:\n",
    "        print(w)\n",
    "    print()\n",
    "\n",
    "    chain.remove_word(word_1)\n",
    "    for w in chain:\n",
    "        print(w)\n",
    "    print()\n",
    "\n",
    "    chain.remove_word(word_3)\n",
    "    chain.remove_word(word_4)\n",
    "    print('removed all')\n",
    "    for w in chain:\n",
    "        print(w)\n",
    "    print('showed all')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\" at 1 (<None> <None>)\n",
      "\"1\" at 1 (<None> <None>)\n",
      "first: \"1\" at 1 (<None> <None>)\n",
      "last: \"1\" at 1 (<None> <None>)\n",
      "\n",
      "\"2\" at 2 (<None> <None>)\n",
      "\"2\" at 2 (<\"1\" at 1> <None>)\n",
      "\"1\" at 1 (<None> <\"2\" at 2>)\n",
      "first: \"1\" at 1 (<None> <\"2\" at 2>)\n",
      "last: \"2\" at 2 (<\"1\" at 1> <None>)\n",
      "\n",
      "\"3\" at 3 (<None> <None>)\n",
      "\"3\" at 3 (<\"2\" at 2> <None>)\n",
      "\"1\" at 1 (<None> <\"2\" at 2>)\n",
      "\"2\" at 2 (<\"1\" at 1> <\"3\" at 3>)\n",
      "first: \"1\" at 1 (<None> <\"2\" at 2>)\n",
      "last: \"3\" at 3 (<\"2\" at 2> <None>)\n",
      "\n",
      "\"1\" at 1 (<None> <\"2\" at 2>)\n",
      "\"2\" at 2 (<\"1\" at 1> <\"3\" at 3>)\n",
      "\"3\" at 3 (<\"2\" at 2> <None>)\n",
      "\n",
      "chain [\n",
      "\"1\" at 1 (<None> <\"2\" at 2>)\n",
      "\"2\" at 2 (<\"1\" at 1> <\"3\" at 3>)\n",
      "\"3\" at 3 (<\"2\" at 2> <None>)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "test_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\" at 1 (<None> <\"2\" at 2>)\n",
      "\"2\" at 2 (<\"1\" at 1> <\"3\" at 3>)\n",
      "\"3\" at 3 (<\"2\" at 2> <None>)\n",
      "\n",
      "\"1\" at 1 (<None> <\"3\" at 3>)\n",
      "\"3\" at 3 (<\"1\" at 1> <\"4\" at 4>)\n",
      "\"4\" at 4 (<\"3\" at 3> <None>)\n",
      "\n",
      "\"1\" at 1 (<None> <\"3\" at 3>)\n",
      "\"3\" at 3 (<\"1\" at 1> <\"4\" at 4>)\n",
      "\"4\" at 4 (<\"3\" at 3> <None>)\n",
      "\n",
      "\"3\" at 3 (<None> <\"4\" at 4>)\n",
      "\"4\" at 4 (<\"3\" at 3> <None>)\n",
      "\n",
      "removed all\n",
      "showed all\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение списка цепочек слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.helpers import parse_chains_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_3():\n",
    "    text = 'tomorrow I have a meeting with Tim Hanks Tom Crus and Eastwud'\n",
    "    chains = parse_chains_of_words(text)\n",
    "    for chain in chains:\n",
    "        print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain [\n",
      "\"Tim\" at 31 (<None> <\"Hanks\" at 35>)\n",
      "\"Hanks\" at 35 (<\"Tim\" at 31> <\"Tom\" at 41>)\n",
      "\"Tom\" at 41 (<\"Hanks\" at 35> <\"Crus\" at 45>)\n",
      "\"Crus\" at 45 (<\"Tom\" at 41> <None>)\n",
      "]\n",
      "chain [\n",
      "\"Eastwud\" at 54 (<None> <None>)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "test_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.jaro import jaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333332\n",
      "0.6851851851851851\n",
      "0.557142857142857\n",
      "0.8690476190476191\n"
     ]
    }
   ],
   "source": [
    "print(jaro('Tom Cruise', 'Tom Crus'))\n",
    "print(jaro('Tom Cruise', 'Tom Hanks'))\n",
    "print(jaro('Clint Eastwood', 'Eastwud'))\n",
    "print(jaro('Eastwood', 'Eastwud'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправление 1: проверка на схожесть с контекстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.corrector import SimilarityChecker\n",
    "from handlers.helpers import parse_chains_of_words, split_context_by_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [\n",
    "    'John Wayne', 'Tom Hanks', 'Tom Cruise', 'Clint Eastwood',\n",
    "    'Jon Hamm', 'John Nolan', 'William', 'Fischer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': ['John Wayne', 'Tom Hanks', 'Tom Cruise', 'Clint Eastwood', 'Jon Hamm', 'John Nolan'], '1': ['William', 'Fischer']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divided_context = split_context_by_length(context)\n",
    "print(divided_context)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain [\n",
      "\"Tim\" at 31 (<None> <\"Hanks\" at 35>)\n",
      "\"Hanks\" at 35 (<\"Tim\" at 31> <\"Tom\" at 41>)\n",
      "\"Tom\" at 41 (<\"Hanks\" at 35> <\"Crus\" at 45>)\n",
      "\"Crus\" at 45 (<\"Tom\" at 41> <None>)\n",
      "]\n",
      "chain [\n",
      "\"Eastwud\" at 54 (<None> <\"John\" at 62>)\n",
      "\"John\" at 62 (<\"Eastwud\" at 54> <\"Wayne\" at 67>)\n",
      "\"Wayne\" at 67 (<\"John\" at 62> <\"Tom\" at 73>)\n",
      "\"Tom\" at 73 (<\"Wayne\" at 67> <\"Tim\" at 77>)\n",
      "\"Tim\" at 77 (<\"Tom\" at 73> <\"Hanks\" at 81>)\n",
      "\"Hanks\" at 81 (<\"Tim\" at 77> <\"Fiser\" at 87>)\n",
      "\"Fiser\" at 87 (<\"Hanks\" at 81> <None>)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "text = 'tomorrow I have a meeting with Tim Hanks Tom Crus and Eastwud John Wayne Tom Tim Hanks Fiser'\n",
    "chains = parse_chains_of_words(text)\n",
    "for chain in chains:\n",
    "    print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_similarity(chain, context_list, probability_limit, is_surname_and_name):\n",
    "    if len(context_list) != 0:\n",
    "        print(is_surname_and_name)\n",
    "        checker = SimilarityChecker(context_list, probability_limit, is_surname_and_name)\n",
    "        checker.check(chain)\n",
    "        return checker.entered_list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_surname_and_name = True for surname and name indeed\n",
      "True\n",
      "0:\"Eastwud\" 1:\"John\"\n",
      "1:\"John\" 2:\"Wayne\" (1.000000 \"John Wayne\")\n",
      "2:\"Wayne\" 3:\"Tom\"\n",
      "3:\"Tom\" 4:\"Tim\" (0.738095 \"Tom Cruise\")\n",
      "4:\"Tim\" 5:\"Hanks\" (0.925926 \"Tom Hanks\")\n",
      "5:\"Hanks\" 6:\"Fiser\"\n",
      "\n",
      "is_surname_and_name = False for surname and name indeed\n",
      "False\n",
      "0:\"Eastwud\"\n",
      "1:\"John\" (0.800000 \"John Wayne\")\n",
      "2:\"Wayne\"\n",
      "3:\"Tom\" (0.777778 \"Tom Hanks\")\n",
      "4:\"Tim\"\n",
      "5:\"Hanks\"\n",
      "6:\"Fiser\"\n"
     ]
    }
   ],
   "source": [
    "check_context = divided_context.get('2', [])\n",
    "probability_limit = 0.7\n",
    "\n",
    "print('is_surname_and_name = True for surname and name indeed')\n",
    "is_surname_and_name = True\n",
    "similarity_probabilities = read_similarity(chains[1], check_context, probability_limit, is_surname_and_name)\n",
    "for element in similarity_probabilities:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('is_surname_and_name = False for surname and name indeed')\n",
    "is_surname_and_name = False\n",
    "similarity_probabilities = read_similarity(chains[1], check_context, probability_limit, is_surname_and_name)\n",
    "for element in similarity_probabilities:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0:\"Eastwud\"\n",
      "1:\"John\"\n",
      "2:\"Wayne\"\n",
      "3:\"Tom\"\n",
      "4:\"Tim\"\n",
      "5:\"Hanks\"\n",
      "6:\"Fiser\" (0.904762 \"Fischer\")\n"
     ]
    }
   ],
   "source": [
    "check_context = divided_context.get('1', [])\n",
    "probability_limit = 0.7\n",
    "is_surname_and_name = False\n",
    "\n",
    "similarity_probabilities = read_similarity(chains[1], check_context, probability_limit, is_surname_and_name)\n",
    "\n",
    "for element in similarity_probabilities:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0:\"Eastwud\" 1:\"John\"\n",
      "1:\"John\" 2:\"Wayne\" (1.000000 \"John Wayne\")\n",
      "2:\"Wayne\" 3:\"Tom\"\n",
      "3:\"Tom\" 4:\"Tim\"\n",
      "4:\"Tim\" 5:\"Hanks\" (0.925926 \"Tom Hanks\")\n",
      "5:\"Hanks\" 6:\"Fiser\"\n"
     ]
    }
   ],
   "source": [
    "check_context = divided_context.get('2', [])\n",
    "probability_limit = 0.8\n",
    "is_surname_and_name = True\n",
    "\n",
    "similarity_probabilities = read_similarity(chains[1], check_context, probability_limit, is_surname_and_name)\n",
    "\n",
    "for element in similarity_probabilities:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправление 2: упорядочивание по вероятности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.corrector import SimilarityChecker, read_similarity\n",
    "from handlers.helpers import parse_chains_of_words, split_context_by_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [\n",
    "    'John Wayne', 'Tom Hanks', 'Tom Cruise', 'Clint Eastwood',\n",
    "    'Jon Hamm', 'John Nolan', 'William', 'Fischer'\n",
    "]\n",
    "divided_context = split_context_by_length(context)\n",
    "\n",
    "text = 'tomorrow I have a meeting with Tim Hanks Tom Crus and Eastwud John Wayne Tom Tim Hanks Fiser'\n",
    "chains = parse_chains_of_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0:\"Eastwud\" 1:\"John\"\n",
      "1:\"John\" 2:\"Wayne\" (1.000000 \"John Wayne\")\n",
      "2:\"Wayne\" 3:\"Tom\"\n",
      "3:\"Tom\" 4:\"Tim\" (0.738095 \"Tom Cruise\")\n",
      "4:\"Tim\" 5:\"Hanks\" (0.925926 \"Tom Hanks\")\n",
      "5:\"Hanks\" 6:\"Fiser\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_context = divided_context.get('2', [])\n",
    "probability_limit = 0.7\n",
    "is_surname_and_name = True\n",
    "\n",
    "similarity_probabilities = read_similarity(chains[1], check_context, probability_limit, is_surname_and_name)\n",
    "for element in similarity_probabilities:\n",
    "    print(element)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:\"Hanks\" 6:\"Fiser\"\n",
      "2:\"Wayne\" 3:\"Tom\"\n",
      "0:\"Eastwud\" 1:\"John\"\n",
      "3:\"Tom\" 4:\"Tim\" (0.738095 \"Tom Cruise\")\n",
      "4:\"Tim\" 5:\"Hanks\" (0.925926 \"Tom Hanks\")\n",
      "1:\"John\" 2:\"Wayne\" (1.000000 \"John Wayne\")\n"
     ]
    }
   ],
   "source": [
    "similarity_probabilities.sort()\n",
    "for element in similarity_probabilities:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\"John\" 2:\"Wayne\" (1.000000 \"John Wayne\")\n",
      "4:\"Tim\" 5:\"Hanks\" (0.925926 \"Tom Hanks\")\n",
      "3:\"Tom\" 4:\"Tim\" (0.738095 \"Tom Cruise\")\n",
      "0:\"Eastwud\" 1:\"John\"\n",
      "2:\"Wayne\" 3:\"Tom\"\n",
      "5:\"Hanks\" 6:\"Fiser\"\n"
     ]
    }
   ],
   "source": [
    "similarity_probabilities.sort(reverse=True)\n",
    "for element in similarity_probabilities:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправление 3: поиск исправлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.corrector import Corrector\n",
    "from handlers.helpers import parse_chains_of_words, split_context_by_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [\n",
    "    'John Wayne', 'Tom Hanks', 'Tom Cruise', 'Clint Eastwood',\n",
    "    'Jon Hamm', 'John Nolan', 'William', 'Fischer'\n",
    "]\n",
    "divided_context = split_context_by_length(context)\n",
    "\n",
    "text = 'tomorrow I have a meeting with Tim Hanks Tom Crus and Eastwud John Wayne Tom Tim Hanks Fiser'\n",
    "chains = parse_chains_of_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4:\"Tim\" 5:\"Hanks\" (0.925926 \"Tom Hanks\")\n",
      "\n",
      "chain [\n",
      "\"Eastwud\" at 54 (<None> <\"Tom\" at 73>)\n",
      "\"Tom\" at 73 (<\"Eastwud\" at 54> <\"Fiser\" at 87>)\n",
      "\"Fiser\" at 87 (<\"Tom\" at 73> <None>)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "check_context = divided_context.get('2', [])\n",
    "probability_limit = 0.7\n",
    "is_surname_and_name = True\n",
    "\n",
    "corrector = Corrector(check_context, probability_limit, is_surname_and_name)\n",
    "corrections = corrector.correct(chains[1])\n",
    "for element in corrections:\n",
    "    print(element)\n",
    "print()\n",
    "print(chains[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\"Tom\" 2:\"Fiser\" (0.812963 \"Tom Cruise\")\n",
      "\n",
      "chain [\n",
      "\"Eastwud\" at 54 (<None> <None>)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "corrections = corrector.correct(chains[1])\n",
    "for element in corrections:\n",
    "    print(element)\n",
    "print()\n",
    "print(chains[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
